model:
  rng_seed: 42
  model_type: 'global_univariate_cnn_ae_lstm'
  model_config:
    hyperparameter_tuning_range:
      hidden_size: [ 1, 100 ]
      number_of_layers: [ 1, 2 ]
      dropout: [ 0.0, 0.4 ]
      recurrent_dropout: [0.0, 0.4]
      optimizer_name: [ 'RMSprop', 'Adam' ]
      learning_rate: [ 1e-7, 1e-2 ]
      number_of_epochs: [ 1, 40 ]
      batch_size: [ 32, 32 ]
      input_window_size: 10
      output_window_size: 7 # must be equal output_window_size
      multi_variable_nr: 1 # must be equal to number of variables used in multi variable (1 if uni variate)
      number_of_features: 1 # must be equal to number of features in data
      number_of_trials: 200 # Number of tuning trials to run. The more the better.
      #time_to_tune_in_minutes: 6000  # Time to tune in minutes, If both number of trials or time to tune is set, first one to finnish.
      stateful_lstm: true
    common_parameters_for_all_models:
      should_shuffle_batches: False
      batch_size: 32
      input_window_size: 10
      output_window_size: 7
      multi_variable_nr: 1
      lstm-shared:
        input_window_size: 10
        output_window_size: 7
        multi_variable_nr: 1
      lstm:
        optimizer_name: 'Adam'
        stateful_lstm: True
        loss: "mae"
        learning_rate: 0.0016146453106769651
        number_of_features: 1
        epochs: 15
        layers:
          - hidden_size: 62
            dropout: 3.4171700927954074e-05
            recurrent_dropout: 0.3563995834345084
      ae:
        optimizer_name: 'Adam'
        loss: "mae"
        learning_rate: 0.0001
        epochs: 100
      encoder:
        - layer: "Conv1d"
          filters: 64
          kernel_size: 3
          activation: "relu"
        - layer: "Conv1d"
          filters: 64
          kernel_size: 5
          activation: "relu"
      decoder:
        - layer: "Conv1dTranspose"
          kernel_size: 5
          filters: 64
          activation: "relu"
        - layer: "Conv1dTranspose"
          kernel_size: 3
          filters: 1

    model_structure:
      - 12532
      - 11694
      - 11716
      - 11950
      - 11195
      - 11998
      - 274
      - 11407
      - 46
      - 11326
      - 11335
      - 12197
      - 11693
      - 11780
      - 12502
      - 11866
      - 11400
      - 12256
      - 10320
      - 10030
