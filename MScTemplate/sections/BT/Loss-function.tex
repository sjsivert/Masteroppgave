\subsection{Loss functions}
\label{loss-functions}
\cite{Russel2012} defines loss functions as such:
A \textit{loss function} $L(x, y, \hat{y})$ is defined as the amount of utility lost by predicting 
$h(x)=\hat{y}$ when the correct answer is $f(x) = y$ and $h$ is the heuristic function.
This is the most general formulation of the loss function. Often a simplified version is used,
$L(y, \hat{y})$, that is independent of x.

This means, that the loss function is the function that calculates the error between the 
models prediction, and the actual target value.
This chapter will breafly give an explanation for common loss functions.


\todo[inline]{Burde vi skrive litt mer p√• hvert avsnitt?}
\subsubsection{MSE}
% Common loss functions
The most commonly used loss function for regression problem is the 
\textbf{Mean Squared Error (MSE)} function in \autoref{eq:mean-squared-error}.
It is the mathematically preferred function if the target distribution is Guassian.
It punishes large errors much more harshly than smaller errors, due to its squaring of the error.
\begin{equation}
  \label{eq:mean-squared-error}
  MSE = \frac{1}{n} \sum_{t=1}^n e_t^2
\end{equation}

\subsubsection{MAE}
If the target distribution consists of outliers, then the 
\textbf{Mean Absolute Error (MAE)} in \autoref{eq:mean-absolute-error} is more appropriate
as it does not punish the outliers too much.

\begin{equation}
  \label{eq:mean-absolute-error}
  MSE = \frac{1}{n} \sum_{t=1}^n |e_t|
\end{equation}

\subsubsection{sMAPE}
\todo[inline]{Trenger vi skrive om dette? }
\begin{equation}
  \label{eq:sMape}
  SMAPE = \frac{1}{n} \sum_{t=1}^n \frac{|\hat{y_t} - y_t|}{(y_t + \hat{y_t}) / 2}
\end{equation}


