\section{Results}
\label{section:discussion&results:experiment-results}
TODO: Write introduction
% Dataset 1
\subsection{Dataset 1}
% Results
\import{./tables/results/dataset_1}{Average-metric-dataset-1.tex}
% T-test smapev
% T-test smapev
\import{./tables/results/ttest}{ttest-p-values-lstm-experiments-sMAPE.tex}
\import{./tables/results/ttest}{ttest-p-values-main-experiments-sMAPE.tex}
% \import{./tables/results/ttest}{ttest-p-values-lstm-experiments-MASE.tex}

\begin{figure}[h!]
  \centering
  \begin{subfigure}[b]{0.49\textwidth}
    \includegraphics[width=\textwidth]{./figs/results/boxplot/mase-dataset_1.png}
    \hfill
    \caption{MASE boxplot of predictions made on dataset 1}
    \label{fig:results:boxplot-mase-dataset-1-mase}
  \end{subfigure}
  \begin{subfigure}[b]{0.49\textwidth}
    \includegraphics[width=\textwidth]{./figs/results/boxplot/smape-dataset_1.png}
    \hfill
    \caption{sMAPE boxplot of predictions made on dataset 1}
    \label{fig:results:boxplot-mase-dataset-1-smape}

  \end{subfigure}
\end{figure}
% \begin{figure}[h!]
%   \centering
%   \includegraphics[width=\textwidth]{./figs/results/boxplot/smape-dataset_1.png}
%   \hfill
%   \caption{sMAPE boxplot of predictions made on dataset 1}
%   \label{fig:results:boxplot-mase-dataset-1-smape}
% \end{figure}

\Cref{table:Average-metric-dataset-1} shows the mean metrics across
all the time series in dataset 1. The poorest perfoming model across the board
is SARIMA, with a MASE of $1.294$, sMAPE of $0.239$ and 7-day MASE of $1.063$.
All the different LSTM structures and hybrid methods outperformed SARIMA.

The multivariate models outperformed all their retrospective univariate counter partners.
The global univariate LSTM outperforms the local univariate on both MASE and sMAPE, though not statistically significant,
but this results is not reproduced for the multivariate models, or the CNN-AE-LSTM models.

All the model structures perfoms slightly better with our proposed CNN-AE-LSTM method on dataset 1, except for
the global univariate CNN-AE-LSTM.

The most consistent models with the least amount of variance are the multivariate models.
The local multivariate CNN-AE-LSTM and the local multivariate LSTM were the only two models
who beat the naive 7-day prediction. The best performing model is the local multivariate CNN-AE-LSTM.

The mean MASE dataset across all models on dataset 1 is $0.971$,
the mean sMAPE is $0.2034$,
and the mean MASE 7-day is $0.9976$.


\subsection{Dataset 2}
% Dataset 2

\begin{samepage}
  \import{./tables/results/dataset_2}{Average-metric-dataset-2.tex}
  \begin{figure}[ht!]
    \centering
    \begin{subfigure}[b]{0.49\textwidth}
      \includegraphics[width=\textwidth]{./figs/results/boxplot/mase-dataset_2.png}
      \hfill
      \caption{Boxplot of predictions made on dataset 2}
      \label{fig:results:boxplot-mase-dataset-2-mase}
    \end{subfigure}
    \begin{subfigure}[b]{0.49\textwidth}
      \includegraphics[width=\textwidth]{./figs/results/boxplot/smape-dataset_2.png}
      \hfill
      \caption{sMAPE boxplot of predictions made on dataset 2}
      \label{fig:results:boxplot-mase-dataset-2-smape}
    \end{subfigure}
  \end{figure}
\end{samepage}

Compared to dataset 1, dataset 2 proved to be a much more difficult dataset to forecast.
Compared to the NN models SARIMA performs a lot better, with a mase of $1.472$, a 7-day MASE of $0.707$ and smape of $0.633$.
Some of the results from dataset 1 are reproduced on dataset 2. For example the global univariate LSTM outperform
the local univariate LSTM. The multivariate models outperforms the univariate models.
On dataset 2 however all the CNN-AE-LSTM methods performs poorly compared to the LSTM models.
The best performing model on dataset 2 is local multivariate LSTM with a mase of $1.377$ a sMAPAE of $0.603$
and $0.697$.

The mean MASE across dataset 2 is $1.652$,
the mean sMAPE is $0.697$,
and the mean MASE 7-day is  $0.7306$.

% Dataset 3
\subsection{Dataset 3}
\begin{samepage}
  \import{./tables/results/dataset_seasonal}{Average-metric-dataset-3.tex}
  \begin{figure}[h!]
    \centering
    \begin{subfigure}[b]{0.49\textwidth}
      \includegraphics[width=\textwidth]{./figs/results/boxplot/mase-dataset_3.png}
      \hfill
      \caption{Boxplot of predictions made on seasonal dataset}
      \label{fig:results:boxplot-mase-dataset-3}

    \end{subfigure}
    \begin{subfigure}[b]{0.49\textwidth}
      \includegraphics[width=\textwidth]{./figs/results/boxplot/smape-dataset_3.png}
      \hfill
      \caption{Boxplot of predictions made on seasonal dataset}
      \label{fig:results:boxplot-smape-dataset-3}
    \end{subfigure}
  \end{figure}
\end{samepage}
On dataset 3 SARIMA, again, outperforms the purely local univariate LSTM baseline.
Many of the same patterns repeats on dataset 3 as with dataset 1 and 2, multivariate beats univariate,
global unviariate beats local univariate.
On dataset 3 it seems that the CNN-AE-LSTMs outperforms the LSTMs once again, except for the
best perfoming model, which is the local multivariate LSTM.


\todo[inline]{Update mean values! They are old}
The mean MASE for dataset 3 is $2.009$,
the mean sMAPE data set 3 is $0.4362$,
and the mean MASE 7-day is $1.131$.



% Globale modeller er dårligere på mase 7 bortsett fra.
% All results tables

\subsection{Model Comparisons Across Datasets}
Our results suffer from low sample size and high variance, so it isn't easy
to prove anything statistically. Aggregating the results across the datasets
increases our sample size, improving the statistical tests.

\todo[inline]{Add tabl description \Cref{table:ttest-p-values-lstm-experiments-sMAPE-all-dataset}: l-u = local univariate, l-m= local multivariate, g-u = global univariate etc..}
\import{./tables/results/}{Average-metric-all-datasets.tex}
\import{./tables/results/ttest}{ttest-p-values-lstm-experiments-sMAPE-all-dataset.tex}
\begin{figure}
  \begin{subfigure}[b]{0.49\textwidth}
    \includegraphics[width=\textwidth]{./figs/results/barplot/MASE-all-dataset.png}
    \hfill
    \caption{Boxplot of predictions made on seasonal dataset}
    % \label{fig:results:boxplot-mase-dataset-3}
  \end{subfigure}
  \begin{subfigure}[b]{0.49\textwidth}
    \includegraphics[width=\textwidth]{./figs/results/barplot/sMAPE-all-dataset.png}
    \hfill
    \caption{Boxplot of predictions made on seasonal dataset}
    % \label{fig:results:boxplot-mase-dataset-3}

  \end{subfigure}
\end{figure}

% \subsubsection{Local Versus Global}
From dataset 1, the global univariate LSTM improves the local univariate
LSTM by $2.4\%$, however, can be random with a p-value of $0.712$.
When we compare both model structures across all the datasets,
our global model improves by $4.43\%$ relative to the local model,
and our p-value falls to $0.362$. Even though this is not low enough
to be below our threshold value of $0.05$, it does show a promising trend.


% \subsubsection{Univariate Versus Multivariate}
The local multivariate LSTM shows a big improvement over the local univariate LSTM,
with a perfomance increase of $13.74\%$ across all datasets and with a
low p-value of $0.039$.

% \subsubsection{Global Multivariate Versus Global Univariate}
The global LSTM improves by $3.07\%$, with a p-value of $0.193$, by making the global univariate model to a global multivariate model.
But the global multivariate model performs worse than the local multivariate model with $-7.33\%$ with a p-value of $0.238$.

\todo[inline]{Should comment on the CNN-AE-LSTM vs the LSTM as well.}

% Comparing local vs global
%mean smape local: 0.451
%
%mean smape global: 0.431
%
%improvement: 4.43\%
%
%p-value: 0.362
%
%% Comparing uni vs multi
%mean smape local: 0.451
%
%mean smape multi: 0.389
%
%improvement: 13.74\%
%
%p-value: 0.039
%
%