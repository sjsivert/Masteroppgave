\chapter{Method}
\label{section:Method}

With the aim of implementation and evaluation of a new predictive method,

This chapter introduces the implemented method and methodology used in the practical research of time series prediction.
Initially, section \Cref{section:Method:Arima} and \Cref{section:Method:LSTM} presents the use and tuning of baseline methods needed in order to validate our method.
\dots

\section{Software and Hardware}
\todo[inline]{Add source for python, Keras, Pandas and genpipes, pmdarima}
\todo[inline]{Should the software paragraphs be a part of the method implementation, and leav hardware alone?}

% Software
The framework and experiments are implemented using python 3.8 [TODO: Add source].
The SARIMA method is created using the pmdarima library and statsmodels library,
supporting both running the experiments and tuning with auto-aria [TODO: Add source for both].
On the other hand, the machine learning library Keras and Tensorflow is used in order to implement the deep learning methods used such as the LSTM method [TODO: Add Keras and TF source].

When loading data into the experiments, data pipelines were created using the genpipes library.
After this, data manipulation was conducted using the Pandas library, as well as the numpy library.


% Hardware
The hardware available for running experiments consists of two work-stations.
The first work-station consists of a AMD Ryzen 5 5600X prosessor and 32 GB 32000 MHz memory with Windows 11 and Linux Sub-system for linux,
while the secound work-station consists of an Intel i9-9900K processor and 16 GB 2666 MHz memory, Windows 10 and Linux Sub-system for linux.
Both of these work-stations were used for tuning and execution of experiments in this project.

\section{Loss function and Metrics}
Here we describe which loss function and metrics we use.

\subsection*{Loss function}
Since our datasets often contains a lot of outliers we decided not to use the well known
Mean Squared Error (MSE) [\Cref{section:BT:Loss}].
We used Mean Absolute Error (MAE) while training the neural networks.
Some experiments were done using both MASE and sMASE, but MAE did perform better.

\subsection*{Metrics}
Since we are working with multiple time-series and each time-series might differ in scale.
When choosing an error metric, we have to accommodate a number of factors.
Since our time-series are of different scales, we cannot use a scale-dependent metric
like MSE or MAE.


We use MASE with 1 day naive forecast, as well as MASE with a 7 day
naive forecast. This is because the 1 day naive forecast is a regular metric used
and can give a good impresion of how the model performs.
However, a 7 day naive forecast will more closely reperesent a real-worl application measure,
as in reality, we do not have the information available to make a MASE measurement for a 7 day prediction.

A problem with MASE is that if a time series follows a random walk
then the best forecast will always be the naive forecast. MASE is therefore dependent of
how good the naive prediction is.
Therefore we also include sMASE as a metric.
sMASE will give a better impression of how well the our predicted forecasts fits the target values,
independently of the naive forecast.
In the chosen datasets zero values occur rarely so we can use sMAPE without
being afraid of division by zero [\Cref{section:BT:Loss}].


\import{./sections/Method/}{Experiment-framework.tex}
\import{./sections/Method/}{pytorch-vs-keras.tex}

\import{./sections/Method/}{DataProcessing.tex}

% \import{./sections/Method/}{issues-with-lstm.tex}

\import{./sections/Method/}{SARIMA.tex}
\import{./sections/Method/}{LSTM-method.tex}
\import{./sections/Method/}{AE.tex}
\import{./sections/Method/}{CNNAE-LSTM.tex}
